{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b4203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Documents\\anaconda3\\envs\\taswiyahmn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40bf1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WELFake_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2049be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      Unnamed: 0                                              title  \\\n",
       "0             0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1             1                                                NaN   \n",
       "2             2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3             3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4             4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "..          ...                                                ...   \n",
       "495         495  Trump ordered to give deposition in Washington...   \n",
       "496         496  Obama’s Race War Makes Its Way To His Hometown...   \n",
       "497         497  FACTBOX: About 6.1 million without power in U....   \n",
       "498         498  OOPS! ABSOLUTELY NO ONE SHOWED UP For NYC Debu...   \n",
       "499         499  Russia warns Iraq, Kurds not to destabilize Mi...   \n",
       "\n",
       "                                                  text  label  \n",
       "0    No comment is expected from Barack Obama Membe...      1  \n",
       "1       Did they post their votes for Hillary already?      1  \n",
       "2     Now, most of the demonstrators gathered last ...      1  \n",
       "3    A dozen politically active pastors came here f...      0  \n",
       "4    The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
       "..                                                 ...    ...  \n",
       "495  WASHINGTON (Reuters) - A Washington judge has ...      0  \n",
       "496  This is insane!WATCH: Protests erupted in Chic...      1  \n",
       "497  (Reuters) - Power outages from Hurricane Irma ...      0  \n",
       "498  I was in Nordstrom yesterday when our salesper...      1  \n",
       "499  MOSCOW (Reuters) - Russia on Wednesday warned ...      0  \n",
       "\n",
       "[500 rows x 4 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.head(500)\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e813ab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Preprocessing:\n",
      "   Unnamed: 0                                              title  \\\n",
      "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
      "1           1                                                NaN   \n",
      "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
      "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
      "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
      "\n",
      "                                                text  label  \n",
      "0  No comment is expected from Barack Obama Membe...      1  \n",
      "1     Did they post their votes for Hillary already?      1  \n",
      "2   Now, most of the demonstrators gathered last ...      1  \n",
      "3  A dozen politically active pastors came here f...      0  \n",
      "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Preprocessing:\")\n",
    "print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e02f6e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8816\\2337446204.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  df['text'] = df['text'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8816\\2337446204.py:4: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  df['text'] = df['text'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df.dropna()\n",
    "\n",
    "df['text'] = df['text'].astype(str)\n",
    "df['text'] = df['text'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'[^A-Za-z0-9\\s]', '', x))\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6db9f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].astype(str)  # Convert all values to string (force conversion)\n",
    "df = df[df[\"text\"] != \"nan\"]  # Remove \"nan\" stored as a string\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)  # Drop real NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b34d7650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Preprocessing:\n",
      "   Unnamed: 0                                              title  \\\n",
      "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
      "1           1                                                NaN   \n",
      "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
      "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
      "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
      "\n",
      "                                                text  label  \n",
      "0  comment expect barack obama member fyf fukyofl...      1  \n",
      "1                          post vote hillari alreadi      1  \n",
      "2  demonstr gather last night exercis constitut p...      1  \n",
      "3  dozen polit activ pastor came privat dinner fr...      0  \n",
      "4  rs sarmat missil dub satan replac ss fli mile ...      1  \n"
     ]
    }
   ],
   "source": [
    "print(\"After Preprocessing:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "745f87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(df.loc[325, \"text\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f81a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"preprocessed_data_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7fd1b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_data_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4f7e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, title, text, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"text\"].isnull()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a78417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df[['text', 'label']])\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "train_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Further split the training set into train (90%) and validation (10%)\n",
    "train_val_split = train_test_split[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_val_split[\"train\"],\n",
    "    \"validation\": train_val_split[\"test\"],\n",
    "    \"test\": train_test_split[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d939a3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 355\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 99\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "692406dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████| 355/355 [00:06<00:00, 53.78 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 67.02 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████| 99/99 [00:02<00:00, 44.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8601393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 15:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.667117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.575006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.667272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.492273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.426300</td>\n",
       "      <td>0.497556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 12:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4975564479827881,\n",
       " 'eval_runtime': 5.6824,\n",
       " 'eval_samples_per_second': 7.039,\n",
       " 'eval_steps_per_second': 0.176,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",  \n",
    "    logging_steps=10,  \n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=3e-5 \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8537fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77fe256a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./final_model\\\\tokenizer_config.json',\n",
       " './final_model\\\\special_tokens_map.json',\n",
       " './final_model\\\\vocab.txt',\n",
       " './final_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./final_model\")\n",
    "tokenizer.save_pretrained(\"./final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98f9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimulai dari sini\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"./final_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf35868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Breaking: Scientists discover a cure for aging\"\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "with torch.no_grad():  \n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b9a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
